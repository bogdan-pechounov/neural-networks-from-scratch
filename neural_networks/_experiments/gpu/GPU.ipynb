{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5gNEJmNraHz"
      },
      "outputs": [],
      "source": [
        "from numba import njit, cuda, prange\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def add_one(A):\n",
        "  m, n = A.shape\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      A[i][j] += 1\n",
        "\n",
        "@njit\n",
        "def add_one_optimized(A):\n",
        "  m, n = A.shape\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      A[i][j] += 1\n",
        "\n",
        "@njit(parallel=True)\n",
        "def add_one_parallel(A):\n",
        "  m, n = A.shape\n",
        "  for i in prange(m):\n",
        "    for j in prange(n):\n",
        "      A[i][j] += 1\n",
        "\n",
        "@cuda.jit\n",
        "def add_one_gpu(A):\n",
        "  x, y = cuda.grid(2) # coordinates of current gpu core\n",
        "  m, n = A.shape\n",
        "  # since gpu cores are assigned in blocks, x and y might be bigger than m and n\n",
        "  if x < m and y < n: \n",
        "    # one gpu core is responsible for one addition\n",
        "    A[x, y] += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.zeros((10_000, 10_000))\n",
        "\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (math.ceil(A.shape[0] / threads_per_block[0]) , math.ceil(A.shape[1] / threads_per_block[1]))\n",
        "\n",
        "A_gpu = cuda.to_device(A)\n",
        "add_one_gpu[blocks_per_grid, threads_per_block](A_gpu)\n",
        "A_gpu.copy_to_host(A)\n",
        "A_gpu.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEBuH3oAcH9v",
        "outputId": "8f02fd08-7947-4313-fad0-5cfacbad7faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f5aa2cfda30>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.zeros((10, 10))\n",
        "\n",
        "# compile function\n",
        "# add_one_optimized(np.zeros((10, 10)))\n",
        "# add_one_parallel(np.zeros((10, 10)))\n",
        "\n",
        "# define the number of gpu cores/threads in a block\n",
        "threads_per_block = (16, 16) # a block of gpu cores can have very fast access to some shared memory\n",
        "blocks_per_grid_x = math.ceil(A.shape[0] / threads_per_block[0]) \n",
        "blocks_per_grid_y = math.ceil(A.shape[1] / threads_per_block[1])\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y) # number of blocks in total\n",
        "# move the array from host memory (cpu) to device memory (gpu)\n",
        "A_gpu = cuda.to_device(A)\n",
        "\n",
        "\n",
        "# %timeit add_one(A)\n",
        "%timeit add_one_optimized(A)\n",
        "%timeit add_one_parallel(A)\n",
        "# %timeit add_one_gpu[blocks_per_grid, threads_per_block](A) # A will need to be moved to gpu each call\n",
        "%timeit add_one_gpu[blocks_per_grid, threads_per_block](A_gpu) # much faster if A is already in gpu\n",
        "%timeit A + 1"
      ],
      "metadata": {
        "id": "vJIxO9ghcGeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcec814-4ebe-4c7b-cf66-35fd2121c9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 13.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "2.27 µs ± 3.38 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "The slowest run took 8.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "5.14 µs ± 6.35 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37.6 µs ± 756 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "1.22 µs ± 404 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba.cuda.cudadrv import enums\n",
        "from numba import cuda\n",
        "\n",
        "device = cuda.get_current_device()\n",
        "attribs= [name.replace(\"CU_DEVICE_ATTRIBUTE_\", \"\") for name in dir(enums) if name.startswith(\"CU_DEVICE_ATTRIBUTE_\")]\n",
        "for attr in attribs:\n",
        "    print(attr, '=', getattr(device, attr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUl40tTCxHtc",
        "outputId": "428faed7-ff96-4950-8760-5caba8d9fa63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASYNC_ENGINE_COUNT = 3\n",
            "CAN_MAP_HOST_MEMORY = 1\n",
            "CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM = 1\n",
            "CLOCK_RATE = 1590000\n",
            "COMPUTE_CAPABILITY_MAJOR = 7\n",
            "COMPUTE_CAPABILITY_MINOR = 5\n",
            "COMPUTE_MODE = 0\n",
            "COMPUTE_PREEMPTION_SUPPORTED = 1\n",
            "CONCURRENT_KERNELS = 1\n",
            "CONCURRENT_MANAGED_ACCESS = 1\n",
            "COOPERATIVE_LAUNCH = 1\n",
            "COOPERATIVE_MULTI_DEVICE_LAUNCH = 1\n",
            "ECC_ENABLED = 1\n",
            "GLOBAL_L1_CACHE_SUPPORTED = 1\n",
            "GLOBAL_MEMORY_BUS_WIDTH = 256\n",
            "GPU_OVERLAP = 1\n",
            "HOST_NATIVE_ATOMIC_SUPPORTED = 0\n",
            "INTEGRATED = 0\n",
            "IS_MULTI_GPU_BOARD = 0\n",
            "KERNEL_EXEC_TIMEOUT = 0\n",
            "L2_CACHE_SIZE = 4194304\n",
            "LOCAL_L1_CACHE_SUPPORTED = 1\n",
            "MANAGED_MEMORY = 1\n",
            "MAX_BLOCK_DIM_X = 1024\n",
            "MAX_BLOCK_DIM_Y = 1024\n",
            "MAX_BLOCK_DIM_Z = 64\n",
            "MAX_GRID_DIM_X = 2147483647\n",
            "MAX_GRID_DIM_Y = 65535\n",
            "MAX_GRID_DIM_Z = 65535\n",
            "MAX_MAX_TEXTURE_2D_MIPMAPPED_HEIGHT = 32768\n",
            "MAX_PITCH = 2147483647\n",
            "MAX_REGISTERS_PER_BLOCK = 65536\n",
            "MAX_REGISTERS_PER_MULTIPROCESSOR = 65536\n",
            "MAX_SHARED_MEMORY_PER_BLOCK = 49152\n",
            "MAX_SHARED_MEMORY_PER_BLOCK_OPTIN = 65536\n",
            "MAX_SHARED_MEMORY_PER_MULTIPROCESSOR = 65536\n",
            "MAX_SURFACE_1D_LAYERED_LAYERS = 2048\n",
            "MAX_SURFACE_1D_LAYERED_WIDTH = 32768\n",
            "MAX_SURFACE_1D_WIDTH = 32768\n",
            "MAX_SURFACE_2D_HEIGHT = 65536\n",
            "MAX_SURFACE_2D_LAYERED_HEIGHT = 32768\n",
            "MAX_SURFACE_2D_LAYERED_LAYERS = 2048\n",
            "MAX_SURFACE_2D_LAYERED_WIDTH = 32768\n",
            "MAX_SURFACE_2D_WIDTH = 131072\n",
            "MAX_SURFACE_3D_DEPTH = 16384\n",
            "MAX_SURFACE_3D_HEIGHT = 16384\n",
            "MAX_SURFACE_3D_WIDTH = 16384\n",
            "MAX_SURFACE_CUBEMAP_LAYERED_LAYERS = 2046\n",
            "MAX_SURFACE_CUBEMAP_LAYERED_WIDTH = 32768\n",
            "MAX_SURFACE_CUBEMAP_WIDTH = 32768\n",
            "MAX_TEXTURE_1D_LAYERED_LAYERS = 2048\n",
            "MAX_TEXTURE_1D_LAYERED_WIDTH = 32768\n",
            "MAX_TEXTURE_1D_LINEAR_WIDTH = 268435456\n",
            "MAX_TEXTURE_1D_MIPMAPPED_WIDTH = 32768\n",
            "MAX_TEXTURE_1D_WIDTH = 131072\n",
            "MAX_TEXTURE_2D_GATHER_HEIGHT = 32768\n",
            "MAX_TEXTURE_2D_GATHER_WIDTH = 32768\n",
            "MAX_TEXTURE_2D_HEIGHT = 65536\n",
            "MAX_TEXTURE_2D_LAYERED_HEIGHT = 32768\n",
            "MAX_TEXTURE_2D_LAYERED_LAYERS = 2048\n",
            "MAX_TEXTURE_2D_LAYERED_WIDTH = 32768\n",
            "MAX_TEXTURE_2D_LINEAR_HEIGHT = 65000\n",
            "MAX_TEXTURE_2D_LINEAR_PITCH = 2097120\n",
            "MAX_TEXTURE_2D_LINEAR_WIDTH = 131072\n",
            "MAX_TEXTURE_2D_MIPMAPPED_WIDTH = 32768\n",
            "MAX_TEXTURE_2D_WIDTH = 131072\n",
            "MAX_TEXTURE_3D_DEPTH = 16384\n",
            "MAX_TEXTURE_3D_DEPTH_ALT = 32768\n",
            "MAX_TEXTURE_3D_HEIGHT = 16384\n",
            "MAX_TEXTURE_3D_HEIGHT_ALT = 8192\n",
            "MAX_TEXTURE_3D_WIDTH = 16384\n",
            "MAX_TEXTURE_3D_WIDTH_ALT = 8192\n",
            "MAX_TEXTURE_CUBEMAP_LAYERED_LAYERS = 2046\n",
            "MAX_TEXTURE_CUBEMAP_LAYERED_WIDTH = 32768\n",
            "MAX_TEXTURE_CUBEMAP_WIDTH = 32768\n",
            "MAX_THREADS_PER_BLOCK = 1024\n",
            "MAX_THREADS_PER_MULTI_PROCESSOR = 1024\n",
            "MEMORY_CLOCK_RATE = 5001000\n",
            "MULTIPROCESSOR_COUNT = 40\n",
            "MULTI_GPU_BOARD_GROUP_ID = 0\n",
            "PAGEABLE_MEMORY_ACCESS = 0\n",
            "PCI_BUS_ID = 0\n",
            "PCI_DEVICE_ID = 4\n",
            "PCI_DOMAIN_ID = 0\n",
            "SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO = 32\n",
            "STREAM_PRIORITIES_SUPPORTED = 1\n",
            "SURFACE_ALIGNMENT = 512\n",
            "TCC_DRIVER = 0\n",
            "TEXTURE_ALIGNMENT = 512\n",
            "TEXTURE_PITCH_ALIGNMENT = 32\n",
            "TOTAL_CONSTANT_MEMORY = 65536\n",
            "UNIFIED_ADDRESSING = 1\n",
            "WARP_SIZE = 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "\n",
        "compute_capability_to_cores_per_SM = {\n",
        "    (2,0) : 32,\n",
        "    (2,1) : 48,\n",
        "    (3,0) : 192,\n",
        "    (3,5) : 192,\n",
        "    (3,7) : 192,\n",
        "    (5,0) : 128,\n",
        "    (5,2) : 128,\n",
        "    (6,0) : 64,\n",
        "    (6,1) : 128,\n",
        "    (7,0) : 64,\n",
        "    (7,5) : 64,\n",
        "    (8,0) : 64,\n",
        "    (8,6) : 128,\n",
        "    (8,9) : 128,\n",
        "    (9,0) : 128\n",
        "}\n",
        "\n",
        "device = cuda.get_current_device()\n",
        "SM_count = device.MULTIPROCESSOR_COUNT\n",
        "compute_capability = device.compute_capability\n",
        "cores_per_SM = compute_capability_to_cores_per_SM[compute_capability]\n",
        "total_cores = cores_per_SM * SM_count\n",
        "print(\"GPU compute capability: \" , compute_capability)\n",
        "print(\"GPU number of streaming multiprocessors: \" , SM_count)\n",
        "print(\"Total cores: \" , total_cores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25zRmR8caSpd",
        "outputId": "595c8e07-c9bf-423e-d813-2a56e5af977a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability:  (7, 5)\n",
            "GPU number of streaming multiprocessors:  40\n",
            "Total cores:  2560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import njit, cuda\n",
        "import math\n",
        "\n",
        "@njit\n",
        "def matrix_multiplication_optimized(A, B):\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  C = np.zeros((m, p))\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      for k in range(p):\n",
        "        C[i, k] += A[i, j] * B[j, k]\n",
        "  return C\n",
        "\n",
        "@njit\n",
        "def matrix_multiplication_optimized2(A, B):\n",
        "  # this loop order is slower, probably less cache friendly\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  C = np.zeros((m, p))\n",
        "  for i in range(m):\n",
        "    for k in range(p):\n",
        "      for j in range(n):\n",
        "        C[i, k] += A[i, j] * B[j, k]\n",
        "  return C\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_multiplication_gpu(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  print(i)\n",
        "  if i < m and k < p:\n",
        "    for j in range(n):\n",
        "      C[i, k] += A[i, j] * B[j, k]\n",
        "\n",
        "m = 1000\n",
        "n = 1000\n",
        "p = 1000\n",
        "A = np.random.randn(m, n)\n",
        "B = np.random.randn(n, p)\n",
        "C = np.zeros((m, p))\n",
        "\n",
        "# compile function\n",
        "# matrix_multiplication_optimized(A, B)\n",
        "# matrix_multiplication_optimized2(A, B)\n",
        "\n",
        "# gpu \n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "C_gpu = cuda.to_device(C)\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (math.ceil(C.shape[0]/threads_per_block[0]), math.ceil(C.shape[1]/threads_per_block[1]))\n",
        "\n",
        "%timeit matrix_multiplication_optimized(A, B)\n",
        "%timeit matrix_multiplication_optimized2(A, B)\n",
        "%timeit matrix_multiplication_gpu[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "%timeit A @ B"
      ],
      "metadata": {
        "id": "3YbxG1BmHteL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a2c114-7661-4f87-ef63-dd19a07ba824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12 s ± 834 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "1.72 s ± 360 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "87 µs ± 55.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "100 ms ± 9.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import  cuda\n",
        "\n",
        "A = np.random.randn(1000, 1000)\n",
        "A_gpu = cuda.to_device(A)\n",
        "%timeit cuda.to_device(A)\n",
        "%timeit cuda.to_device(A.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMkdsdLRYhdn",
        "outputId": "fc74bd6a-8888-495c-dd18-e9ca76c229f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4 ms ± 46.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "2.29 ms ± 31 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_T_GPU = cuda.to_device(A.T)\n",
        "A_T_GPU.strides = (8000, 8)\n",
        "A_gpu.strides, A_T_GPU.strides"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa_A75-kbOK2",
        "outputId": "c715c302-13b6-4983-8050-1df7295e264a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 8), (8000, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_gpu[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlnidEPJcec",
        "outputId": "0bda7b5b-290a-4ec2-b87d-dba09579a52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0404635120476469"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeEbPlFPFDaq",
        "outputId": "759719d8-95b6-47f7-e04e-145a3ccdceb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f2c5c045ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_gpu.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pICWjTZFhSn",
        "outputId": "f30f17bd-b6a9-4640-a026-eb7006874b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f2c5c0605e0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_gpu[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDRZydXOFFOq",
        "outputId": "85b52e42-2135-49ad-fc3d-04fd40e191ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.7500656246407504"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_gpu.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-QVEcINItSA",
        "outputId": "0856b17a-1206-4e0b-9b2d-f6ed4e9cbd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit A.T\n",
        "%timeit A_gpu.T\n",
        "%timeit A.shape\n",
        "%timeit A_gpu.shape\n",
        "%timeit A[0][0]\n",
        "%timeit A_gpu[0][0]\n",
        "%timeit A[0, 0]\n",
        "%timeit A_gpu[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xttzn2laFHZj",
        "outputId": "0a7f291d-ce2a-43fc-b4b6-8ca66ec4f699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 ns ± 29.7 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
            "134 ms ± 20.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "65.8 ns ± 1.48 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
            "38 ns ± 0.642 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
            "298 ns ± 120 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
            "188 µs ± 46.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "98.2 ns ± 1.19 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
            "77.3 µs ± 13.7 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, int32\n",
        "\n",
        "a = np.arange(1_000)\n",
        "a_gpu = cuda.to_device(a)\n",
        "n = len(a)\n",
        "\n",
        "@cuda.jit\n",
        "def sum_reduce_gpu(a): # assume 1 block\n",
        "  # thread id within a 1D block (position relative to a block)\n",
        "  thread_id = cuda.threadIdx.x\n",
        "  # Create an array in shared memory\n",
        "  shared_array = cuda.shared.array(n, int32) # shape needs to be a \"simple constant\", len(a) won't work\n",
        "  # each thread is responsible for copying one value\n",
        "  shared_array[thread_id] = a[thread_id]\n",
        "  # wait for all threads to finish\n",
        "  cuda.syncthreads()\n",
        "  \n",
        "  step_size = 1\n",
        "  while step_size < n:\n",
        "    if thread_id % (2 * step_size) == 0 and thread_id + step_size < n:\n",
        "      shared_array[thread_id] += shared_array[thread_id + step_size]\n",
        "    step_size *= 2\n",
        "    # wait for all threads to finish to make sure shared_array[thread_id + step_size] has been updated\n",
        "    cuda.syncthreads()\n",
        "  \n",
        "  # one thread is responsible for writing the result\n",
        "  if thread_id == 0:\n",
        "    # store the result in a\n",
        "    a[thread_id] = shared_array[0]\n",
        "\n",
        "sum_reduce_gpu[1, n](a_gpu)\n",
        "print(a.sum(), a_gpu[0])"
      ],
      "metadata": {
        "id": "xJg88D-yBE-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6a3f1c-8139-4819-c8a5-49301a072b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "499500 499500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit sum_reduce_gpu[1, n](a_gpu)\n",
        "%timeit a.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lUcUiBXm4FK",
        "outputId": "66937002-336e-4603-de37-21cc453b3ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39.2 µs ± 817 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "2.48 µs ± 156 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.sin(a)\n",
        "%timeit np.sin(a_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yWd_dP-mW3X",
        "outputId": "1378beb5-44b5-4b38-89b5-d091e00e29cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.2 µs ± 4.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "77.4 µs ± 27.8 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "from numba.types import int32\n",
        "\n",
        "# generate data\n",
        "a = cuda.to_device(np.arange(1024))\n",
        "nelem = len(a)\n",
        "\n",
        "@cuda.jit\n",
        "def array_sum(data):\n",
        "    tid = cuda.threadIdx.x\n",
        "    size = len(data)\n",
        "\n",
        "    if tid < size:\n",
        "        i = cuda.grid(1)\n",
        "\n",
        "        # Declare an array in shared memory\n",
        "        shr = cuda.shared.array(nelem, int32)\n",
        "        shr[tid] = data[i]\n",
        "\n",
        "        # Ensure writes to shared memory are visible\n",
        "        # to all threads before reducing\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        s = 1\n",
        "        while s < cuda.blockDim.x:\n",
        "            if tid % (2 * s) == 0:\n",
        "                # Stride by `s` and add\n",
        "                shr[tid] += shr[tid + s]\n",
        "            s *= 2\n",
        "            cuda.syncthreads()\n",
        "\n",
        "        # After the loop, the zeroth  element contains the sum\n",
        "        if tid == 0:\n",
        "            data[tid] = shr[tid]\n",
        "\n",
        "array_sum[2, 1024](a)\n",
        "print(a[0])                  # 523776\n",
        "print(sum(np.arange(1024)))  # 523776"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15MweiUMuA9p",
        "outputId": "cffd2a2d-34ba-4cdc-9344-971d78b8952a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "523776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64\n",
        "import math\n",
        "\n",
        "@cuda.jit\n",
        "def test(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "\n",
        "@cuda.jit((float64[:], float64[:], float64[:]))\n",
        "def test2(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "\n",
        "m = 1\n",
        "n = 1\n",
        "p = 1\n",
        "A = np.random.randn(m, n)\n",
        "B = np.random.randn(n, p)\n",
        "C = np.zeros((m, p))\n",
        "\n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "C_gpu = cuda.to_device(C)\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (math.ceil(C.shape[0]/threads_per_block[0]), math.ceil(C.shape[1]/threads_per_block[1]))\n",
        "\n",
        "%timeit -r2 test[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu) # more variance because of compile time\n",
        "%timeit -r2 test[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "\n",
        "%timeit -r2 test2[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "%timeit -r2 test2[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pw-NozbzkCS",
        "outputId": "79250de1-7764-4740-ecb3-8aefbc8c8583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278 µs ± 34.3 µs per loop (mean ± std. dev. of 2 runs, 1000 loops each)\n",
            "249 µs ± 4.58 µs per loop (mean ± std. dev. of 2 runs, 10000 loops each)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96.8 µs ± 2.96 µs per loop (mean ± std. dev. of 2 runs, 10000 loops each)\n",
            "95.9 µs ± 1.55 µs per loop (mean ± std. dev. of 2 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64\n",
        "import math\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_multiplication(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  if i < m and k < p:\n",
        "    for j in range(n):\n",
        "      C[i, k] += A[i, j] * B[j, k]\n",
        "\n",
        "m = 100\n",
        "n = 100\n",
        "p = 100\n",
        "A = np.random.randn(m, n)\n",
        "B = np.random.randn(n, p)\n",
        "C = np.zeros((m, p))\n",
        "\n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "C_gpu = cuda.to_device(C)\n",
        "threads_per_block = (33, 33)\n",
        "blocks_per_grid = (math.ceil(C.shape[0]/threads_per_block[0]), math.ceil(C.shape[1]/threads_per_block[1]))\n",
        "\n",
        "matrix_multiplication[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "B6qonE3CNKCk",
        "outputId": "422639f1-54a9-42d6-ed09-d5769d16148c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 16 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "ERROR:numba.cuda.cudadrv.driver:Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CudaAPIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2d09b9dd20bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mblocks_per_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mthreads_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mthreads_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmatrix_multiplication\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks_per_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads_per_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0m\u001b[1;32m    492\u001b[0m                                     self.stream, self.sharedmem)\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_for_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# Invoke kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         driver.launch_kernel(cufunc.handle,\n\u001b[0m\u001b[1;32m    280\u001b[0m                              \u001b[0;34m*\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                              \u001b[0;34m*\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[0;34m(cufunc_handle, gx, gy, gz, bx, by, bz, sharedmem, hstream, args, cooperative)\u001b[0m\n\u001b[1;32m   2550\u001b[0m                                          params_for_launch)\n\u001b[1;32m   2551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2552\u001b[0;31m         driver.cuLaunchKernel(cufunc_handle,\n\u001b[0m\u001b[1;32m   2553\u001b[0m                               \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m                               \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ctypes_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDA_LOG_API_ARGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDA_ERROR_NOT_INITIALIZED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_cuda_python_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCudaAPIError\u001b[0m: [1] Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64\n",
        "import math\n",
        "\n",
        "@cuda.jit((float64[:,::1], float64[:,::1], float64[:,::1]))\n",
        "def matrix_multiplication(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  if i < m and k < p:\n",
        "    for j in range(n):\n",
        "      C[i, k] += A[i, j] * B[j, k]\n",
        "\n",
        "# TPB x TPB threads per block\n",
        "TPB = 16 \n",
        "\n",
        "@cuda.jit\n",
        "def matrix_multiplication_shared(A, B, C):\n",
        "  # create small arrays in shared memory, all threads in a block use the same sA and sB\n",
        "  # shape and type need to be known at compile time\n",
        "  sA = cuda.shared.array(shape=(TPB, TPB), dtype=float64)\n",
        "  sB = cuda.shared.array(shape=(TPB, TPB), dtype=float64)\n",
        "\n",
        "  # absolute position\n",
        "  x, y = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "\n",
        "  if x < m and y < p:\n",
        "    # position of thread relative to a block\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "\n",
        "    # bpg x bpg blocks per grid\n",
        "    bpg = cuda.gridDim.x # grid has \"width\" of x blocks\n",
        "\n",
        "    # loop over rows of A and columns of B in blocks  \n",
        "    for i in range(bpg):\n",
        "      # copy values to shared array\n",
        "      sA[tx, ty] = A[x, ty + i * TPB] if ty + i * TPB < n else 0\n",
        "      sB[tx, ty] = B[tx + i * TPB, y] if tx + i * TPB < n else 0\n",
        "\n",
        "      # wait for other threads in block to finish writing\n",
        "      cuda.syncthreads()\n",
        "\n",
        "      # sum over row tx of sA and column ty of sB\n",
        "      for j in range(TPB):\n",
        "        # partial product with sA and sB\n",
        "        # eventually will go through the entire row of A and entire column of B\n",
        "        C[x, y] += sA[tx, j] * sB[j, ty]\n",
        "\n",
        "      # wait for other threads in block to finish writing\n",
        "      cuda.syncthreads()\n",
        "    \n",
        "m = 1000\n",
        "n = 1000\n",
        "p = 1000\n",
        "A = np.random.randn(m, n)\n",
        "B = np.random.randn(n, p)\n",
        "C = np.zeros((m, p))\n",
        "\n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "C_gpu = cuda.to_device(C)\n",
        "threads_per_block = (TPB, TPB)\n",
        "blocks_per_grid = (math.ceil(C.shape[0]/threads_per_block[0]), math.ceil(C.shape[1]/threads_per_block[1]))\n",
        "\n",
        "print(matrix_multiplication.signatures)\n",
        "%timeit -r1 matrix_multiplication[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "matrix_multiplication.signatures\n",
        "# %timeit matrix_multiplication_shared[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "%timeit -r1 A @ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "nakS40ou63MW",
        "outputId": "a3a15bb7-bf1a-43e5-97f7-29adf690cae3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array(float64, 2d, C), array(float64, 2d, C), array(float64, 2d, C))]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-50e0cd8e7656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_multiplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r1 matrix_multiplication[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mmatrix_multiplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# %timeit matrix_multiplication_shared[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0m\u001b[1;32m    492\u001b[0m                                     self.stream, self.sharedmem)\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_for_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# Invoke kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         driver.launch_kernel(cufunc.handle,\n\u001b[0m\u001b[1;32m    280\u001b[0m                              \u001b[0;34m*\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                              \u001b[0;34m*\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[0;34m(cufunc_handle, gx, gy, gz, bx, by, bz, sharedmem, hstream, args, cooperative)\u001b[0m\n\u001b[1;32m   2550\u001b[0m                                          params_for_launch)\n\u001b[1;32m   2551\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2552\u001b[0;31m         driver.cuLaunchKernel(cufunc_handle,\n\u001b[0m\u001b[1;32m   2553\u001b[0m                               \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m                               \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ctypes_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64\n",
        "import math\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_multiplication(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  if i < m and k < p:\n",
        "    C[i, k] = 0\n",
        "    for j in range(n):\n",
        "      C[i, k] += A[i, j] * B[j, k]\n",
        "\n",
        "@cuda.jit((float64[:,::1], float64[:,::1], float64[:,::1]))\n",
        "def matrix_multiplication2(A, B, C):\n",
        "  i, k = cuda.grid(2)\n",
        "  m, n = A.shape\n",
        "  _, p = B.shape\n",
        "  if i < m and k < p:\n",
        "    C[i, k] = 0\n",
        "    for j in range(n):\n",
        "      C[i, k] += A[i, j] * B[j, k]\n",
        "    \n",
        "m = 1000\n",
        "n = 1000\n",
        "p = 1000\n",
        "A = np.random.randn(m, n)\n",
        "B = np.random.randn(n, p)\n",
        "C = np.empty((m, p))\n",
        "\n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "C_gpu = cuda.to_device(C)\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (math.ceil(C.shape[0]/threads_per_block[0]), math.ceil(C.shape[1]/threads_per_block[1]))\n",
        "\n",
        "print(matrix_multiplication.signatures)\n",
        "%timeit -r2 matrix_multiplication[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "print(matrix_multiplication.signatures, C_gpu[0, 0]) # at first I didn't reset C[i, k] to 0\n",
        "\n",
        "print(matrix_multiplication2.signatures)\n",
        "%timeit -r2 -n10 matrix_multiplication2[blocks_per_grid, threads_per_block](A_gpu, B_gpu, C_gpu)\n",
        "print(matrix_multiplication2.signatures, C_gpu[0, 0])\n",
        "\n",
        "%timeit A @ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvRnhGxl9VMV",
        "outputId": "392dd2ae-4333-4cf6-e343-32cfb2ca3808"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "58.1 ms ± 733 µs per loop (mean ± std. dev. of 2 runs, 1000 loops each)\n",
            "[(array(float64, 2d, C), array(float64, 2d, C), array(float64, 2d, C))] -41.794449001530275\n",
            "[(array(float64, 2d, C), array(float64, 2d, C), array(float64, 2d, C))]\n",
            "The slowest run took 4.30 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "140 µs ± 87.2 µs per loop (mean ± std. dev. of 2 runs, 10 loops each)\n",
            "[(array(float64, 2d, C), array(float64, 2d, C), array(float64, 2d, C))] -41.794449001530275\n",
            "50.8 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    }
  ]
}